{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4649d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Experiment utilities for the EV Stag Hunt model.\n",
    "\n",
    "Contains policy factory functions, trial runners, multiprocessing helpers,\n",
    "and standalone plotting routines. Depends on `ev_core` for the model.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "from typing import Callable, Dict, Optional, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "\n",
    "from ev_core import (\n",
    "    EVStagHuntModel,\n",
    "    set_initial_adopters,\n",
    "    final_mean_adoption_vs_ratio,\n",
    "    phase_sweep_X0_vs_ratio,\n",
    ")\n",
    "from ev_plotting import (\n",
    "    plot_fanchart,\n",
    "    plot_spaghetti,\n",
    "    plot_density,\n",
    "    plot_ratio_sweep,\n",
    "    plot_phase_plot,\n",
    ")\n",
    "from ev_core_new import (\n",
    "    run_network_trial,\n",
    "    final_mean_adoption_vs_I0,\n",
    "    phase_sweep_X0_vs_I0,\n",
    ")\n",
    "from ev_experiments_new import (\n",
    "    I0_sweep_df,\n",
    "    phase_sweep_df_I0,\n",
    ")\n",
    "from ev_plotting_new import (\n",
    "    plot_I0_sweep,\n",
    "    plot_phase_plot_I0,\n",
    "    _default_plot_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "26172712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Policy factories\n",
    "# -----------------------------\n",
    "\n",
    "def policy_subsidy_factory(start: int, end: int, delta_a0: float = 0.3, delta_beta_I: float = 0.0) -> Callable:\n",
    "    \"\"\"Create a policy that temporarily boosts coordination payoffs.\n",
    "\n",
    "    Raises `a0` and/or `beta_I` during `[start, end)` and reverts after.\n",
    "    Returns a closure `policy(model, step)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def policy(model, step):\n",
    "        if not hasattr(policy, \"base_a0\"):\n",
    "            policy.base_a0 = model.a0\n",
    "        if not hasattr(policy, \"base_beta_I\"):\n",
    "            policy.base_beta_I = model.beta_I\n",
    "\n",
    "        if start <= step < end:\n",
    "            model.a0 = policy.base_a0 + delta_a0\n",
    "            model.beta_I = policy.base_beta_I + delta_beta_I\n",
    "        else:\n",
    "            model.a0 = policy.base_a0\n",
    "            model.beta_I = policy.base_beta_I\n",
    "\n",
    "    return policy\n",
    "\n",
    "\n",
    "def policy_infrastructure_boost_factory(start: int, boost: float = 0.2, once: bool = True) -> Callable:\n",
    "    \"\"\"Create a policy that injects infrastructure at a specific step.\"\"\"\n",
    "\n",
    "    def policy(model, step):\n",
    "        if step < start:\n",
    "            return\n",
    "        if once:\n",
    "            if not hasattr(policy, \"done\"):\n",
    "                model.infrastructure = float(np.clip(model.infrastructure + boost, 0.0, 1.0))\n",
    "                policy.done = True\n",
    "        else:\n",
    "            model.infrastructure = float(np.clip(model.infrastructure + boost, 0.0, 1.0))\n",
    "\n",
    "    return policy\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Trial runner\n",
    "# -----------------------------\n",
    "\n",
    "def run_timeseries_trial(\n",
    "    T: int = 200,\n",
    "    scenario_kwargs: Optional[Dict] = None,\n",
    "    seed: Optional[int] = None,\n",
    "    policy: Optional[Callable] = None,\n",
    "    strategy_choice_func: str = \"imitate\",\n",
    "    tau: float = 1.0,\n",
    ") -> Tuple[np.ndarray, np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"Run a single simulation and return X(t), I(t), and the model dataframe.\"\"\"\n",
    "\n",
    "    scenario = {\n",
    "        # Either provide `ratio` to pin the initial a_I/b, or explicit `a0`.\n",
    "        # Defaults here mirror the classroom-friendly values.\n",
    "        # If `ratio` is present, we compute `a0 = ratio*b - beta_I*I0`.\n",
    "        \"a0\": 2.0,\n",
    "        \"ratio\": None,\n",
    "        \"beta_I\": 3.0,\n",
    "        \"b\": 1.0,\n",
    "        \"g_I\": 0.1,\n",
    "        \"I0\": 0.05,\n",
    "        \"network_type\": \"random\",\n",
    "        \"n_nodes\": 1000,\n",
    "        \"p\": 0.05,\n",
    "        \"m\": 2,\n",
    "        \"collect\": True,\n",
    "        \"X0_frac\": 0.0,\n",
    "        \"init_method\": \"random\",\n",
    "    }\n",
    "    if scenario_kwargs:\n",
    "        scenario.update(scenario_kwargs)\n",
    "\n",
    "    # Compute a0 from ratio if provided to preserve initial payoff ratio\n",
    "    a0_for_model = scenario[\"a0\"]\n",
    "    if scenario.get(\"ratio\") is not None:\n",
    "        a0_for_model = float(scenario[\"ratio\"]) * float(scenario[\"b\"]) - float(scenario[\"beta_I\"]) * float(scenario[\"I0\"])\n",
    "\n",
    "    model = EVStagHuntModel(\n",
    "        a0=a0_for_model,\n",
    "        beta_I=scenario[\"beta_I\"],\n",
    "        b=scenario[\"b\"],\n",
    "        g_I=scenario[\"g_I\"],\n",
    "        I0=scenario[\"I0\"],\n",
    "        seed=seed,\n",
    "        network_type=scenario[\"network_type\"],\n",
    "        n_nodes=scenario[\"n_nodes\"],\n",
    "        p=scenario[\"p\"],\n",
    "        m=scenario[\"m\"],\n",
    "        collect=True,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "\n",
    "    if scenario.get(\"X0_frac\", 0.0) > 0.0:\n",
    "        set_initial_adopters(\n",
    "            model,\n",
    "            scenario[\"X0_frac\"],\n",
    "            method=scenario.get(\"init_method\", \"random\"),\n",
    "            seed=seed,\n",
    "        )\n",
    "\n",
    "    for t in range(T):\n",
    "        if policy is not None:\n",
    "            policy(model, t)\n",
    "        model.step()\n",
    "\n",
    "    df = model.datacollector.get_model_vars_dataframe().copy()\n",
    "    return df[\"X\"].to_numpy(), df[\"I\"].to_numpy(), df\n",
    "\n",
    "\n",
    "def _timeseries_trial_worker(args_dict: Dict) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Worker for parallel trials that reconstructs closures for policies.\"\"\"\n",
    "    T = args_dict[\"T\"]\n",
    "    scenario_kwargs = args_dict.get(\"scenario_kwargs\", {})\n",
    "    seed = args_dict.get(\"seed\", None)\n",
    "    policy_spec = args_dict.get(\"policy\", None)\n",
    "    strategy_choice_func = args_dict.get(\"strategy_choice_func\", \"imitate\")\n",
    "    tau = args_dict.get(\"tau\", 1.0)\n",
    "\n",
    "    policy = None\n",
    "    if isinstance(policy_spec, dict):\n",
    "        ptype = policy_spec.get(\"type\")\n",
    "        if ptype == \"subsidy\":\n",
    "            policy = policy_subsidy_factory(**policy_spec[\"params\"])\n",
    "        elif ptype == \"infrastructure\":\n",
    "            policy = policy_infrastructure_boost_factory(**policy_spec[\"params\"])\n",
    "\n",
    "    X, I, _df = run_timeseries_trial(\n",
    "        T=T,\n",
    "        scenario_kwargs=scenario_kwargs,\n",
    "        seed=seed,\n",
    "        policy=policy,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "    return X, I\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Experiment: Intervention trials + plotting\n",
    "# -----------------------------\n",
    "\n",
    "def collect_intervention_trials(\n",
    "    n_trials: int = 10,\n",
    "    T: int = 200,\n",
    "    scenario_kwargs: Optional[Dict] = None,\n",
    "    subsidy_params: Optional[Dict] = None,\n",
    "    max_workers: int = 1,\n",
    "    seed_base: int = 42,\n",
    "    strategy_choice_func: str = \"imitate\",\n",
    "    tau: float = 1.0,\n",
    ") -> Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray], pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Run baseline and subsidy trials; return raw trajectories and summary dataframes.\"\"\"\n",
    "\n",
    "    scenario = scenario_kwargs or {}\n",
    "    subsidy = subsidy_params or {\"start\": 30, \"end\": 80, \"delta_a0\": 0.3, \"delta_beta_I\": 0.0}\n",
    "\n",
    "    baseline_args = []\n",
    "    subsidy_args = []\n",
    "    for i in range(n_trials):\n",
    "        seed = seed_base + i\n",
    "        baseline_args.append(\n",
    "            {\n",
    "                \"T\": T,\n",
    "                \"scenario_kwargs\": scenario,\n",
    "                \"seed\": seed,\n",
    "                \"policy\": None,\n",
    "                \"strategy_choice_func\": strategy_choice_func,\n",
    "                \"tau\": tau,\n",
    "            }\n",
    "        )\n",
    "        subsidy_args.append(\n",
    "            {\n",
    "                \"T\": T,\n",
    "                \"scenario_kwargs\": scenario,\n",
    "                \"seed\": seed,\n",
    "                \"policy\": {\"type\": \"subsidy\", \"params\": subsidy},\n",
    "                \"strategy_choice_func\": strategy_choice_func,\n",
    "                \"tau\": tau,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    baseline_X, baseline_I = [], []\n",
    "    subsidy_X, subsidy_I = [], []\n",
    "\n",
    "    # Run sequentially or concurrently\n",
    "    Executor = ThreadPoolExecutor if max_workers == 1 else ProcessPoolExecutor\n",
    "    with Executor(max_workers=max_workers) as ex:\n",
    "        baseline_futs = [ex.submit(_timeseries_trial_worker, args) for args in baseline_args]\n",
    "        subsidy_futs = [ex.submit(_timeseries_trial_worker, args) for args in subsidy_args]\n",
    "        for fut in as_completed(baseline_futs):\n",
    "            X, I = fut.result()\n",
    "            baseline_X.append(X)\n",
    "            baseline_I.append(I)\n",
    "        for fut in as_completed(subsidy_futs):\n",
    "            X, I = fut.result()\n",
    "            subsidy_X.append(X)\n",
    "            subsidy_I.append(I)\n",
    "\n",
    "    # Align order by seed (as_completed may scramble)\n",
    "    baseline_X = sorted(baseline_X, key=lambda arr: tuple(arr))\n",
    "    subsidy_X = sorted(subsidy_X, key=lambda arr: tuple(arr))\n",
    "\n",
    "    # Summary stats\n",
    "    def summarize(X_list: List[np.ndarray]) -> pd.DataFrame:\n",
    "        mat = np.vstack(X_list)\n",
    "        df = pd.DataFrame({\n",
    "            \"X_mean\": mat.mean(axis=0),\n",
    "            \"X_med\": np.median(mat, axis=0),\n",
    "            \"X_q10\": np.quantile(mat, 0.10, axis=0),\n",
    "            \"X_q25\": np.quantile(mat, 0.25, axis=0),\n",
    "            \"X_q75\": np.quantile(mat, 0.75, axis=0),\n",
    "            \"X_q90\": np.quantile(mat, 0.90, axis=0),\n",
    "        })\n",
    "        return df\n",
    "\n",
    "    baseline_df = summarize(baseline_X)\n",
    "    subsidy_df = summarize(subsidy_X)\n",
    "\n",
    "    return baseline_X, baseline_I, subsidy_X, subsidy_I, baseline_df, subsidy_df\n",
    "\n",
    "\n",
    "def traces_to_long_df(baseline_X: List[np.ndarray], subsidy_X: List[np.ndarray]) -> pd.DataFrame:\n",
    "    \"\"\"Convert trajectory lists to a tidy DataFrame: [group, trial, time, X].\"\"\"\n",
    "    rows = []\n",
    "    for trial, X in enumerate(baseline_X):\n",
    "        for t, x in enumerate(X):\n",
    "            rows.append((\"baseline\", trial, t, float(x)))\n",
    "    for trial, X in enumerate(subsidy_X):\n",
    "        for t, x in enumerate(X):\n",
    "            rows.append((\"subsidy\", trial, t, float(x)))\n",
    "    return pd.DataFrame(rows, columns=[\"group\", \"trial\", \"time\", \"X\"])\n",
    "\n",
    "\n",
    "def ratio_sweep_df(\n",
    "    X0_frac: float = 0.40,\n",
    "    ratio_values: Optional[np.ndarray] = None,\n",
    "    scenario_kwargs: Optional[Dict] = None,\n",
    "    T: int = 250,\n",
    "    batch_size: int = 16,\n",
    "    init_noise_I: float = 0.04,\n",
    "    strategy_choice_func: str = \"logit\",\n",
    "    tau: float = 1.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute X* vs ratio and return as a DataFrame.\"\"\"\n",
    "    scenario = {\n",
    "        \"beta_I\": 2.0,\n",
    "        \"b\": 1.0,\n",
    "        \"g_I\": 0.05,\n",
    "        \"I0\": 0.05,\n",
    "        \"network_type\": \"BA\",\n",
    "        \"n_nodes\": 120,\n",
    "        \"p\": 0.05,\n",
    "        \"m\": 2,\n",
    "    }\n",
    "    if scenario_kwargs:\n",
    "        scenario.update(scenario_kwargs)\n",
    "\n",
    "    if ratio_values is None:\n",
    "        ratio_values = np.linspace(0.8, 3.5, 41)\n",
    "\n",
    "    X_means = final_mean_adoption_vs_ratio(\n",
    "        X0_frac,\n",
    "        ratio_values,\n",
    "        I0=scenario[\"I0\"],\n",
    "        beta_I=scenario[\"beta_I\"],\n",
    "        b=scenario[\"b\"],\n",
    "        g_I=scenario[\"g_I\"],\n",
    "        T=T,\n",
    "        network_type=scenario[\"network_type\"],\n",
    "        n_nodes=scenario[\"n_nodes\"],\n",
    "        p=scenario[\"p\"],\n",
    "        m=scenario[\"m\"],\n",
    "        batch_size=batch_size,\n",
    "        init_noise_I=init_noise_I,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "\n",
    "    return pd.DataFrame({\"ratio\": ratio_values, \"X_mean\": X_means})\n",
    "\n",
    "\n",
    "def phase_sweep_df(\n",
    "    max_workers: int | None = None,\n",
    "    backend: str = \"process\",\n",
    "    X0_values: Optional[np.ndarray] = None,\n",
    "    ratio_values: Optional[np.ndarray] = None,\n",
    "    scenario_kwargs: Optional[Dict] = None,\n",
    "    batch_size: int = 16,\n",
    "    init_noise_I: float = 0.04,\n",
    "    T: int = 250,\n",
    "    strategy_choice_func: str = \"logit\",\n",
    "    tau: float = 1.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Compute tidy DataFrame of X* over (X0, ratio).\"\"\"\n",
    "    if X0_values is None:\n",
    "        X0_values = np.linspace(0.0, 1.0, 21)\n",
    "    if ratio_values is None:\n",
    "        ratio_values = np.linspace(0.8, 3.5, 41)\n",
    "\n",
    "    scenario = {\n",
    "        \"I0\": 0.05,\n",
    "        \"beta_I\": 2.0,\n",
    "        \"b\": 1.0,\n",
    "        \"g_I\": 0.05,\n",
    "        \"network_type\": \"BA\",\n",
    "        \"n_nodes\": 120,\n",
    "        \"p\": 0.05,\n",
    "        \"m\": 2,\n",
    "    }\n",
    "    if scenario_kwargs:\n",
    "        scenario.update(scenario_kwargs)\n",
    "\n",
    "    X_final = phase_sweep_X0_vs_ratio(\n",
    "        X0_values,\n",
    "        ratio_values,\n",
    "        I0=scenario[\"I0\"],\n",
    "        beta_I=scenario[\"beta_I\"],\n",
    "        b=scenario[\"b\"],\n",
    "        g_I=scenario[\"g_I\"],\n",
    "        T=T,\n",
    "        network_type=scenario[\"network_type\"],\n",
    "        n_nodes=scenario[\"n_nodes\"],\n",
    "        p=scenario[\"p\"],\n",
    "        m=scenario[\"m\"],\n",
    "        batch_size=batch_size,\n",
    "        init_noise_I=init_noise_I,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "        max_workers=max_workers or 1,\n",
    "        backend=backend,\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for i, X0 in enumerate(X0_values):\n",
    "        for j, ratio in enumerate(ratio_values):\n",
    "            rows.append((float(X0), float(ratio), float(X_final[j, i])))\n",
    "    return pd.DataFrame(rows, columns=[\"X0\", \"ratio\", \"X_final\"])\n",
    "\n",
    "def X0_sweep_df(\n",
    "    ratio: float = 2.3,\n",
    "    X0_values: Optional[np.ndarray] = None,\n",
    "    scenario_kwargs: Optional[Dict] = None,\n",
    "    T: int = 250,\n",
    "    batch_size: int = 16,\n",
    "    init_noise_I: float = 0.04,\n",
    "    strategy_choice_func: str = \"logit\",\n",
    "    tau: float = 1.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sweep over X0 (initial fraction of adopters) and compute final X*.\n",
    "    Returns a DataFrame with columns: X0, X_mean.\n",
    "    \"\"\"\n",
    "    # Base scenario\n",
    "    scenario = {\n",
    "        \"ratio\": ratio,          # <-- fixed ratio (a_I / b)\n",
    "        \"beta_I\": 2.0,\n",
    "        \"b\": 1.0,\n",
    "        \"g_I\": 0.05,\n",
    "        \"I0\": 0.05,\n",
    "        \"network_type\": \"BA\",\n",
    "        \"n_nodes\": 120,\n",
    "        \"p\": 0.05,\n",
    "        \"m\": 2,\n",
    "    }\n",
    "    if scenario_kwargs:\n",
    "        scenario.update(scenario_kwargs)\n",
    "\n",
    "    # Default sweep range if none provided\n",
    "    if X0_values is None:\n",
    "        X0_values = np.linspace(0.0, 1.0, 41)\n",
    "\n",
    "    # Compute X* vs X0\n",
    "    X_means = final_mean_adoption_vs_X0(\n",
    "        X0_values,\n",
    "        ratio=scenario[\"ratio\"],\n",
    "        I0=scenario[\"I0\"],\n",
    "        beta_I=scenario[\"beta_I\"],\n",
    "        b=scenario[\"b\"],\n",
    "        g_I=scenario[\"g_I\"],\n",
    "        T=T,\n",
    "        network_type=scenario[\"network_type\"],\n",
    "        n_nodes=scenario[\"n_nodes\"],\n",
    "        p=scenario[\"p\"],\n",
    "        m=scenario[\"m\"],\n",
    "        batch_size=batch_size,\n",
    "        init_noise_I=init_noise_I,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "\n",
    "    # Build DataFrame\n",
    "    return pd.DataFrame({\"X0\": X0_values, \"X_mean\": X_means})\n",
    "\n",
    "\n",
    "def plot_intervention_fanchart(\n",
    "    baseline_X: List[np.ndarray],\n",
    "    subsidy_X: List[np.ndarray],\n",
    "    out_path: Optional[str] = None,\n",
    ") -> str:\n",
    "    \"\"\"Plot fan charts for baseline and subsidy trials and save to file.\n",
    "\n",
    "    Returns the file path to the saved image.\n",
    "    \"\"\"\n",
    "    T = len(baseline_X[0]) if baseline_X else 0\n",
    "    t = np.arange(T)\n",
    "\n",
    "    def quantiles(X_list: List[np.ndarray]):\n",
    "        mat = np.vstack(X_list)\n",
    "        return {\n",
    "            \"mean\": mat.mean(axis=0),\n",
    "            \"q10\": np.quantile(mat, 0.10, axis=0),\n",
    "            \"q25\": np.quantile(mat, 0.25, axis=0),\n",
    "            \"q75\": np.quantile(mat, 0.75, axis=0),\n",
    "            \"q90\": np.quantile(mat, 0.90, axis=0),\n",
    "            \"final\": mat[:, -1],\n",
    "        }\n",
    "\n",
    "    bq = quantiles(baseline_X)\n",
    "    sq = quantiles(subsidy_X)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(11, 8), constrained_layout=True)\n",
    "\n",
    "    # Baseline fan chart\n",
    "    ax = axes[0, 0]\n",
    "    ax.fill_between(t, bq[\"q10\"], bq[\"q90\"], color=\"steelblue\", alpha=0.15, label=\"10–90%\")\n",
    "    ax.fill_between(t, bq[\"q25\"], bq[\"q75\"], color=\"steelblue\", alpha=0.30, label=\"25–75%\")\n",
    "    for X in baseline_X:\n",
    "        ax.plot(t, X, color=\"steelblue\", alpha=0.10, linewidth=1)\n",
    "    ax.plot(t, bq[\"mean\"], color=\"steelblue\", linewidth=2, label=\"mean\")\n",
    "    ax.set_title(\"Baseline adoption\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"X(t)\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    # Subsidy fan chart\n",
    "    ax = axes[0, 1]\n",
    "    ax.fill_between(t, sq[\"q10\"], sq[\"q90\"], color=\"darkorange\", alpha=0.15, label=\"10–90%\")\n",
    "    ax.fill_between(t, sq[\"q25\"], sq[\"q75\"], color=\"darkorange\", alpha=0.30, label=\"25–75%\")\n",
    "    for X in subsidy_X:\n",
    "        ax.plot(t, X, color=\"darkorange\", alpha=0.10, linewidth=1)\n",
    "    ax.plot(t, sq[\"mean\"], color=\"darkorange\", linewidth=2, label=\"mean\")\n",
    "    ax.set_title(\"Subsidy adoption\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"X(t)\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    # Histograms of final X(T)\n",
    "    axes[1, 0].hist(bq[\"final\"], bins=20, color=\"steelblue\", alpha=0.8)\n",
    "    axes[1, 0].set_title(\"Baseline final adoption X(T)\")\n",
    "    axes[1, 0].set_xlabel(\"X(T)\")\n",
    "    axes[1, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axes[1, 1].hist(sq[\"final\"], bins=20, color=\"darkorange\", alpha=0.8)\n",
    "    axes[1, 1].set_title(\"Subsidy final adoption X(T)\")\n",
    "    axes[1, 1].set_xlabel(\"X(T)\")\n",
    "    axes[1, 1].set_ylabel(\"Count\")\n",
    "\n",
    "    # Save figure\n",
    "    if out_path is None:\n",
    "        out_path = os.path.join(os.getcwd(), \"ev_intervention_fanchart.png\")\n",
    "    fig.savefig(out_path, dpi=140)\n",
    "    plt.close(fig)\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def plot_spaghetti_traces(\n",
    "    baseline_X: List[np.ndarray],\n",
    "    subsidy_X: List[np.ndarray],\n",
    "    *,\n",
    "    max_traces: int = 100,\n",
    "    alpha: float = 0.15,\n",
    "    out_path: Optional[str] = None,\n",
    ") -> str:\n",
    "    \"\"\"Plot raw trajectories as thin, transparent lines for baseline/subsidy.\n",
    "\n",
    "    Shows bifurcation visually: many lines diverging toward 0 or 1 over time.\n",
    "    \"\"\"\n",
    "    # Select random subset for visual clarity\n",
    "    rng = np.random.default_rng(123)\n",
    "    def subset(trajs: List[np.ndarray]) -> List[np.ndarray]:\n",
    "        if len(trajs) <= max_traces:\n",
    "            return trajs\n",
    "        idx = rng.choice(len(trajs), size=max_traces, replace=False)\n",
    "        return [trajs[i] for i in idx]\n",
    "\n",
    "    b_sub = subset(baseline_X)\n",
    "    s_sub = subset(subsidy_X)\n",
    "\n",
    "    T = len(b_sub[0]) if b_sub else 0\n",
    "    t = np.arange(T)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(11, 4.5), constrained_layout=True)\n",
    "\n",
    "    ax = axes[0]\n",
    "    for X in b_sub:\n",
    "        ax.plot(t, X, color=\"steelblue\", alpha=alpha, linewidth=0.8)\n",
    "    ax.set_title(\"Baseline traces\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"X(t)\")\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    ax = axes[1]\n",
    "    for X in s_sub:\n",
    "        ax.plot(t, X, color=\"darkorange\", alpha=alpha, linewidth=0.8)\n",
    "    ax.set_title(\"Subsidy traces\")\n",
    "    ax.set_xlabel(\"Time\")\n",
    "    ax.set_ylabel(\"X(t)\")\n",
    "    ax.set_ylim(0, 1)\n",
    "\n",
    "    if out_path is None:\n",
    "        out_path = os.path.join(os.getcwd(), \"ev_spaghetti.png\")\n",
    "    fig.savefig(out_path, dpi=140)\n",
    "    plt.close(fig)\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def plot_time_evolving_density(\n",
    "    baseline_X: List[np.ndarray],\n",
    "    subsidy_X: List[np.ndarray],\n",
    "    *,\n",
    "    x_bins: int = 50,\n",
    "    time_bins: Optional[int] = None,\n",
    "    out_path: Optional[str] = None,\n",
    ") -> str:\n",
    "    \"\"\"Plot 2D histograms of (time, X) densities for baseline and subsidy.\n",
    "\n",
    "    X-axis: time, Y-axis: adoption X(t), Color: frequency/density of passes.\n",
    "    \"\"\"\n",
    "    if not baseline_X or not subsidy_X:\n",
    "        raise ValueError(\"Need non-empty baseline and subsidy trajectories\")\n",
    "\n",
    "    T = len(baseline_X[0])\n",
    "    if time_bins is None:\n",
    "        time_bins = T\n",
    "\n",
    "    # Flatten (t, X) points across all trials\n",
    "    def flatten_points(trajs: List[np.ndarray]):\n",
    "        t = np.arange(T)\n",
    "        t_all = np.repeat(t, len(trajs))\n",
    "        x_all = np.hstack(trajs)\n",
    "        return t_all, x_all\n",
    "\n",
    "    bt, bx = flatten_points(baseline_X)\n",
    "    st, sx = flatten_points(subsidy_X)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4.8), constrained_layout=True)\n",
    "\n",
    "    hb = axes[0].hist2d(bt, bx, bins=[time_bins, x_bins], range=[[0, T - 1], [0.0, 1.0]], cmap=\"magma\")\n",
    "    axes[0].set_title(\"Baseline density: time vs X(t)\")\n",
    "    axes[0].set_xlabel(\"Time\")\n",
    "    axes[0].set_ylabel(\"X(t)\")\n",
    "    fig.colorbar(hb[3], ax=axes[0], label=\"count\")\n",
    "\n",
    "    hs = axes[1].hist2d(st, sx, bins=[time_bins, x_bins], range=[[0, T - 1], [0.0, 1.0]], cmap=\"magma\")\n",
    "    axes[1].set_title(\"Subsidy density: time vs X(t)\")\n",
    "    axes[1].set_xlabel(\"Time\")\n",
    "    axes[1].set_ylabel(\"X(t)\")\n",
    "    fig.colorbar(hs[3], ax=axes[1], label=\"count\")\n",
    "\n",
    "    if out_path is None:\n",
    "        out_path = os.path.join(os.getcwd(), \"ev_density.png\")\n",
    "    fig.savefig(out_path, dpi=140)\n",
    "    plt.close(fig)\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def run_ratio_sweep_plot(\n",
    "    X0_frac: float = 0.40,\n",
    "    ratio_values: Optional[np.ndarray] = None,\n",
    "    scenario_kwargs: Optional[Dict] = None,\n",
    "    T: int = 250,\n",
    "    batch_size: int = 16,\n",
    "    init_noise_I: float = 0.04,\n",
    "    strategy_choice_func: str = \"logit\",\n",
    "    tau: float = 1.0,\n",
    "    out_path: Optional[str] = None,\n",
    ") -> str:\n",
    "    \"\"\"Sweep ratio values and plot final adoption X* vs a_I/b for a fixed X0.\n",
    "\n",
    "    Calls the core computation helper and saves a simple line plot.\n",
    "    Returns the path to the saved image.\n",
    "    \"\"\"\n",
    "    scenario = {\n",
    "        \"beta_I\": 2.0,\n",
    "        \"b\": 1.0,\n",
    "        \"g_I\": 0.05,\n",
    "        \"I0\": 0.05,\n",
    "        \"network_type\": \"BA\",\n",
    "        \"n_nodes\": 120,\n",
    "        \"p\": 0.05,\n",
    "        \"m\": 2,\n",
    "    }\n",
    "    if scenario_kwargs:\n",
    "        scenario.update(scenario_kwargs)\n",
    "\n",
    "    if ratio_values is None:\n",
    "        ratio_values = np.linspace(0.8, 3.5, 41)\n",
    "\n",
    "    X_means = final_mean_adoption_vs_ratio(\n",
    "        X0_frac,\n",
    "        ratio_values,\n",
    "        I0=scenario[\"I0\"],\n",
    "        beta_I=scenario[\"beta_I\"],\n",
    "        b=scenario[\"b\"],\n",
    "        g_I=scenario[\"g_I\"],\n",
    "        T=T,\n",
    "        network_type=scenario[\"network_type\"],\n",
    "        n_nodes=scenario[\"n_nodes\"],\n",
    "        p=scenario[\"p\"],\n",
    "        m=scenario[\"m\"],\n",
    "        batch_size=batch_size,\n",
    "        init_noise_I=init_noise_I,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    ax.plot(ratio_values, X_means, color=\"tabblue\" if hasattr(plt, \"tabblue\") else \"C0\", lw=2)\n",
    "    ax.set_xlabel(\"a_I / b (ratio)\")\n",
    "    ax.set_ylabel(\"Final adoption X*\")\n",
    "    ax.set_title(f\"X* vs ratio for X0={X0_frac:.2f}\")\n",
    "    ax.set_ylim(0.0, 1.0)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "\n",
    "    if out_path is None:\n",
    "        out_path = os.path.join(os.getcwd(), \"ev_ratio_sweep.png\")\n",
    "    fig.savefig(out_path, dpi=140, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def run_phase_plot_X0_vs_ratio_network(\n",
    "    max_workers: int | None = None,\n",
    "    backend: str = \"process\",\n",
    "    X0_values: Optional[np.ndarray] = None,\n",
    "    ratio_values: Optional[np.ndarray] = None,\n",
    "    scenario_kwargs: Optional[Dict] = None,\n",
    "    batch_size: int = 16,\n",
    "    init_noise_I: float = 0.04,\n",
    "    T: int = 250,\n",
    "    strategy_choice_func: str = \"logit\",\n",
    "    tau: float = 1.0,\n",
    "    out_path: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"Produce a heatmap of X* over (X0, a_I/b) using core sweep helper.\n",
    "\n",
    "    Saves a figure similar to the original model script and returns the path.\n",
    "    \"\"\"\n",
    "    # Defaults aligned with the original phase plot\n",
    "    if X0_values is None:\n",
    "        X0_values = np.linspace(0.0, 1.0, 21)\n",
    "    if ratio_values is None:\n",
    "        ratio_values = np.linspace(0.8, 3.5, 41)\n",
    "\n",
    "    scenario = {\n",
    "        \"I0\": 0.05,\n",
    "        \"beta_I\": 2.0,\n",
    "        \"b\": 1.0,\n",
    "        \"g_I\": 0.05,\n",
    "        \"network_type\": \"BA\",\n",
    "        \"n_nodes\": 120,\n",
    "        \"p\": 0.05,\n",
    "        \"m\": 2,\n",
    "    }\n",
    "    if scenario_kwargs:\n",
    "        scenario.update(scenario_kwargs)\n",
    "\n",
    "    X_final = phase_sweep_X0_vs_ratio(\n",
    "        X0_values,\n",
    "        ratio_values,\n",
    "        I0=scenario[\"I0\"],\n",
    "        beta_I=scenario[\"beta_I\"],\n",
    "        b=scenario[\"b\"],\n",
    "        g_I=scenario[\"g_I\"],\n",
    "        T=T,\n",
    "        network_type=scenario[\"network_type\"],\n",
    "        n_nodes=scenario[\"n_nodes\"],\n",
    "        p=scenario[\"p\"],\n",
    "        m=scenario[\"m\"],\n",
    "        batch_size=batch_size,\n",
    "        init_noise_I=init_noise_I,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "        max_workers=max_workers or 1,\n",
    "        backend=backend,\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    im = plt.imshow(\n",
    "        X_final,\n",
    "        origin=\"lower\",\n",
    "        extent=[X0_values[0], X0_values[-1], ratio_values[0], ratio_values[-1]],\n",
    "        aspect=\"auto\",\n",
    "        vmin=0.0,\n",
    "        vmax=1.0,\n",
    "        cmap=\"plasma\",\n",
    "    )\n",
    "    plt.colorbar(im, label=\"Final adopters X*\")\n",
    "    plt.xlabel(\"X0 (initial adoption)\")\n",
    "    plt.ylabel(\"a_I / b (initial payoff ratio)\")\n",
    "    plt.title(\"Network phase plot: X* over X0 and a_I/b\")\n",
    "\n",
    "    # Overlay initial threshold X = b/a_I => X = 1/ratio\n",
    "    X_thresh = 1.0 / ratio_values\n",
    "    X_thresh_clipped = np.clip(X_thresh, 0.0, 1.0)\n",
    "    plt.plot(\n",
    "        X_thresh_clipped,\n",
    "        ratio_values,\n",
    "        color=\"white\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=1.5,\n",
    "        label=\"X = b / a_I (initial)\",\n",
    "    )\n",
    "\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    if out_path is None:\n",
    "        out_path = os.path.join(os.getcwd(), \"ev_phase_plot.png\")\n",
    "    plt.savefig(out_path, dpi=140, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def run_intervention_example(\n",
    "    n_trials: int = 10,\n",
    "    T: int = 200,\n",
    "    scenario_kwargs: Optional[Dict] = None,\n",
    "    subsidy_params: Optional[Dict] = None,\n",
    "    max_workers: int = 1,\n",
    "    seed_base: int = 42,\n",
    "    strategy_choice_func: str = \"imitate\",\n",
    "    tau: float = 1.0,\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame, str]:\n",
    "    \"\"\"Convenience: collect trials, plot, and return summary + image path.\"\"\"\n",
    "\n",
    "    baseline_X, baseline_I, subsidy_X, subsidy_I, baseline_df, subsidy_df = collect_intervention_trials(\n",
    "        n_trials=n_trials,\n",
    "        T=T,\n",
    "        scenario_kwargs=scenario_kwargs,\n",
    "        subsidy_params=subsidy_params,\n",
    "        max_workers=max_workers,\n",
    "        seed_base=seed_base,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "    )\n",
    "    # Use DataFrame-based plotting to ensure outputs go to plots/\n",
    "    traces_df = traces_to_long_df(baseline_X, subsidy_X)\n",
    "    img_path = plot_fanchart(traces_df)\n",
    "    return baseline_df, subsidy_df, img_path\n",
    "\n",
    "def run_timeseries_trial_hallucination(\n",
    "    T: int,\n",
    "    scenario_kwargs: dict,\n",
    "    *,\n",
    "    strategy_choice_func: str = \"logit\",\n",
    "    tau: float = 1.0,\n",
    "    seed: Optional[int] = None,\n",
    "):\n",
    "    # extract parameters\n",
    "    a0 = scenario_kwargs.get(\"a0\", 2.0)\n",
    "    beta_I = scenario_kwargs.get(\"beta_I\", 2.0)\n",
    "    b = scenario_kwargs.get(\"b\", 1.0)\n",
    "    g_I = scenario_kwargs.get(\"g_I\", 0.05)\n",
    "    I0 = scenario_kwargs.get(\"I0\", 0.05)\n",
    "    X0_frac = scenario_kwargs.get(\"X0_frac\", 0.05)\n",
    "    network_type = scenario_kwargs.get(\"network_type\", \"BA\")\n",
    "    n_nodes = scenario_kwargs.get(\"n_nodes\", 120)\n",
    "    p = scenario_kwargs.get(\"p\", 0.05)\n",
    "    m = scenario_kwargs.get(\"m\", 2)\n",
    "\n",
    "    # create the model (collect=True so datacollector is set up)\n",
    "    model = EVStagHuntModel(\n",
    "        a0=a0,\n",
    "        beta_I=beta_I,\n",
    "        b=b,\n",
    "        g_I=g_I,\n",
    "        I0=I0,\n",
    "        network_type=network_type,\n",
    "        n_nodes=n_nodes,\n",
    "        p=p,\n",
    "        m=m,\n",
    "        strategy_choice_func=strategy_choice_func,\n",
    "        tau=tau,\n",
    "        seed=seed,\n",
    "        collect=True,\n",
    "    )\n",
    "\n",
    "    # FORCE CORRECT INITIALIZATION\n",
    "    set_initial_adopters(\n",
    "        model,\n",
    "        X0_frac=X0_frac,\n",
    "        method=\"random\",\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    # ⭐⭐ CRITICAL NEW LINE ⭐⭐\n",
    "    # Collect BEFORE stepping, so X_series[0] = true initial condition\n",
    "    model.datacollector.collect(model)\n",
    "\n",
    "    # run simulation\n",
    "    for _ in range(T):\n",
    "        model.step()\n",
    "\n",
    "    df = model.datacollector.get_model_vars_dataframe()\n",
    "    X_series = df[\"X\"].values\n",
    "    I_series = df[\"I\"].values\n",
    "\n",
    "    return X_series, I_series, df\n",
    "\n",
    "\n",
    "def combined_time_series(\n",
    "    X0_list,\n",
    "    I0_list,\n",
    "    T=200,\n",
    "    beta_I=2.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots multiple X(t) curves and multiple I(t) curves on separate combined figures.\n",
    "    X0_list and I0_list must be same length or one of them length 1.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- logic for pairing initial conditions ---\n",
    "    if len(X0_list) == len(I0_list):\n",
    "        pairs = list(zip(X0_list, I0_list))\n",
    "    elif len(I0_list) == 1:\n",
    "        pairs = [(X0, I0_list[0]) for X0 in X0_list]\n",
    "    elif len(X0_list) == 1:\n",
    "        pairs = [(X0_list[0], I0) for I0 in I0_list]\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"X0_list and I0_list must be same length, or one must be length 1\"\n",
    "        )\n",
    "\n",
    "    curves_X = []\n",
    "    curves_I = []\n",
    "\n",
    "    # --- run trajectories ---\n",
    "    for (X0, I0) in pairs:\n",
    "        X, I, df = run_timeseries_trial_hallucination(\n",
    "            T=T,\n",
    "            scenario_kwargs={\n",
    "                \"a0\": 0.9,\n",
    "                \"beta_I\": beta_I,\n",
    "                \"b\": 1.0,\n",
    "                \"g_I\": 0.05,\n",
    "                \"I0\": I0,\n",
    "                \"X0_frac\": X0,\n",
    "                \"network_type\": \"random\",\n",
    "                \"n_nodes\": 100,\n",
    "                \"m\": 2,\n",
    "                \"collect\": True,\n",
    "            },\n",
    "            strategy_choice_func=\"logit\",\n",
    "            tau=1.0,\n",
    "        )\n",
    "\n",
    "        curves_X.append(X)\n",
    "        curves_I.append(I)\n",
    "\n",
    "    t = np.arange(len(curves_X[0]))\n",
    "\n",
    "    # ---------------------------------\n",
    "    # COMBINED X(t) WITH STARTING POINTS\n",
    "    # ---------------------------------\n",
    "    plt.figure(figsize=(7,5))\n",
    "\n",
    "    # distinct colors per curve (NO LEGEND NEEDED)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(curves_X)))\n",
    "\n",
    "    for X, c in zip(curves_X, colors):\n",
    "        # Plot the whole trajectory\n",
    "        plt.plot(t, X, lw=2, alpha=0.85, color=c)\n",
    "\n",
    "        # ⭐ Visible starting point at t = 0 ⭐\n",
    "        plt.scatter(0, X[0], s=65, color=c, edgecolor='black', linewidth=0.6)\n",
    "\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Adoption X(t)\")\n",
    "    plt.title(f\"Combined Adoption Dynamics (βI={beta_I})\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    out_X = _default_plot_path(f\"combined_X_curves_betaI_{beta_I}.png\")\n",
    "    plt.savefig(out_X, dpi=160, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # ---------------------------------\n",
    "    # COMBINED I(t) WITH STARTING POINTS\n",
    "    # ---------------------------------\n",
    "    plt.figure(figsize=(7,5))\n",
    "\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(curves_I)))\n",
    "\n",
    "    for I, c in zip(curves_I, colors):\n",
    "        plt.plot(t, I, lw=2, alpha=0.85, color=c)\n",
    "        plt.scatter(0, I[0], s=65, color=c, edgecolor='black', linewidth=0.6)\n",
    "\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Infrastructure I(t)\")\n",
    "    plt.title(f\"Combined Infrastructure Dynamics (βI={beta_I})\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.ylim(0,1)\n",
    "\n",
    "    out_I = _default_plot_path(f\"combined_I_curves_betaI_{beta_I}.png\")\n",
    "    plt.savefig(out_I, dpi=160, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Saved combined X(t) curves to:\", out_X)\n",
    "    print(\"Saved combined I(t) curves to:\", out_I)\n",
    "\n",
    "    return out_X, out_I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66436525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "X0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "I0",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "X_final",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "69700867-f5af-4e1d-b994-e8cc9c332c85",
       "rows": [
        [
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "0.010101010101010102",
         "0.0",
         "0.0"
        ],
        [
         "2",
         "0.020202020202020204",
         "0.0",
         "0.0"
        ],
        [
         "3",
         "0.030303030303030304",
         "0.0",
         "0.0"
        ],
        [
         "4",
         "0.04040404040404041",
         "0.0",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>I0</th>\n",
       "      <th>X_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0   I0  X_final\n",
       "0  0.000000  0.0      0.0\n",
       "1  0.010101  0.0      0.0\n",
       "2  0.020202  0.0      0.0\n",
       "3  0.030303  0.0      0.0\n",
       "4  0.040404  0.0      0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0_values = np.linspace(0.0, 1.0, 100)\n",
    "I0_values = np.linspace(0.0, 1.0, 100)\n",
    "\n",
    "phase_df = phase_sweep_df_I0(\n",
    "    X0_values=X0_values,\n",
    "    I0_values=I0_values,\n",
    "    T=250,\n",
    "    batch_size=12,\n",
    "    strategy_choice_func=\"logit\",\n",
    "    tau=1.0,\n",
    ")\n",
    "\n",
    "phase_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31751c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\leonc\\\\mbd-notebooks\\\\Model-Based-Decisions-Code_2\\\\Assignment 3\\\\plots\\\\ev_phase_plot_I0.png'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_phase_plot_I0(phase_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aeffb5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined X(t) curves to: c:\\Users\\leonc\\mbd-notebooks\\Model-Based-Decisions-Code_2\\Assignment 3\\plots\\combined_X_curves_betaI_0.25.png\n",
      "Saved combined I(t) curves to: c:\\Users\\leonc\\mbd-notebooks\\Model-Based-Decisions-Code_2\\Assignment 3\\plots\\combined_I_curves_betaI_0.25.png\n",
      "Saved combined X(t) curves to: c:\\Users\\leonc\\mbd-notebooks\\Model-Based-Decisions-Code_2\\Assignment 3\\plots\\combined_X_curves_betaI_0.5.png\n",
      "Saved combined I(t) curves to: c:\\Users\\leonc\\mbd-notebooks\\Model-Based-Decisions-Code_2\\Assignment 3\\plots\\combined_I_curves_betaI_0.5.png\n",
      "Saved combined X(t) curves to: c:\\Users\\leonc\\mbd-notebooks\\Model-Based-Decisions-Code_2\\Assignment 3\\plots\\combined_X_curves_betaI_1.0.png\n",
      "Saved combined I(t) curves to: c:\\Users\\leonc\\mbd-notebooks\\Model-Based-Decisions-Code_2\\Assignment 3\\plots\\combined_I_curves_betaI_1.0.png\n",
      "Saved combined X(t) curves to: c:\\Users\\leonc\\mbd-notebooks\\Model-Based-Decisions-Code_2\\Assignment 3\\plots\\combined_X_curves_betaI_2.0.png\n",
      "Saved combined I(t) curves to: c:\\Users\\leonc\\mbd-notebooks\\Model-Based-Decisions-Code_2\\Assignment 3\\plots\\combined_I_curves_betaI_2.0.png\n",
      "Saved combined X(t) curves to: c:\\Users\\leonc\\mbd-notebooks\\Model-Based-Decisions-Code_2\\Assignment 3\\plots\\combined_X_curves_betaI_4.0.png\n",
      "Saved combined I(t) curves to: c:\\Users\\leonc\\mbd-notebooks\\Model-Based-Decisions-Code_2\\Assignment 3\\plots\\combined_I_curves_betaI_4.0.png\n"
     ]
    }
   ],
   "source": [
    "for beta in [0.25, 0.5, 1.0, 2.0, 4.0]:\n",
    "    combined_time_series(\n",
    "        X0_list=np.linspace(0.0, 1.0, 25),\n",
    "        I0_list=np.linspace(0.0, 1.0, 25),\n",
    "        T=200,\n",
    "        beta_I=beta,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc3b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: configuration and default scenarios\n",
    "\n",
    "DEFAULT_SCENARIO = dict(\n",
    "    ratio=2.3,\n",
    "    beta_I=2.0,\n",
    "    b=1.0,\n",
    "    g_I=0.10,\n",
    "    I0=0.05,\n",
    "    network_type=\"BA\",\n",
    "    n_nodes=300,\n",
    "    m=2,\n",
    "    collect=True,\n",
    "    X0_frac=0.5,\n",
    "    init_method=\"random\",\n",
    "    p=0.05,\n",
    ")\n",
    "\n",
    "DEFAULT_SUBSIDY = dict(\n",
    "    start=10,\n",
    "    end=60,\n",
    "    delta_a0=0.4,\n",
    "    delta_beta_I=0.0\n",
    ")\n",
    "\n",
    "DEFAULT_SETTINGS = dict(\n",
    "    n_trials=30,\n",
    "    T=200,\n",
    "    max_workers=1,\n",
    "    seed_base=100,\n",
    "    strategy_choice_func=\"imitate\",\n",
    "    tau=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cac5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: run baseline & subsidy experiment\n",
    "\n",
    "baseline_df, subsidy_df, img_path = run_intervention_example(\n",
    "    n_trials=DEFAULT_SETTINGS[\"n_trials\"],\n",
    "    T=DEFAULT_SETTINGS[\"T\"],\n",
    "    scenario_kwargs=DEFAULT_SCENARIO,\n",
    "    subsidy_params=DEFAULT_SUBSIDY,\n",
    "    max_workers=DEFAULT_SETTINGS[\"max_workers\"],\n",
    "    seed_base=DEFAULT_SETTINGS[\"seed_base\"],\n",
    "    strategy_choice_func=DEFAULT_SETTINGS[\"strategy_choice_func\"],\n",
    "    tau=DEFAULT_SETTINGS[\"tau\"],\n",
    ")\n",
    "\n",
    "print(\"Baseline DF shape:\", baseline_df.shape)\n",
    "print(\"Subsidy DF shape:\", subsidy_df.shape)\n",
    "print(\"Saved image:\", img_path)\n",
    "\n",
    "print(\"Baseline final X_mean:\", float(baseline_df[\"X_mean\"].iloc[-1]))\n",
    "print(\"Subsidy final X_mean:\", float(subsidy_df[\"X_mean\"].iloc[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104837a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Phase sweep\n",
    "\n",
    "phase_df = phase_sweep_df(\n",
    "    max_workers=1,\n",
    "    backend=\"thread\",\n",
    "    X0_values=np.linspace(0.0, 1.0, 21),\n",
    "    ratio_values=np.linspace(0.8, 3.5, 31),\n",
    "    batch_size=8,\n",
    "    T=200,\n",
    "    strategy_choice_func=\"logit\",\n",
    "    tau=1.0,\n",
    ")\n",
    "\n",
    "phase_path = plot_phase_plot(phase_df)\n",
    "print(\"Saved phase plot:\", phase_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee05295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Spaghetti experiment\n",
    "\n",
    "baseline_X, baseline_I, subsidy_X, subsidy_I, baseline_df2, subsidy_df2 = collect_intervention_trials(\n",
    "    n_trials=100,\n",
    "    T=200,\n",
    "    scenario_kwargs=DEFAULT_SCENARIO,\n",
    "    subsidy_params=DEFAULT_SUBSIDY,\n",
    "    max_workers=DEFAULT_SETTINGS[\"max_workers\"],\n",
    "    seed_base=DEFAULT_SETTINGS[\"seed_base\"],\n",
    "    strategy_choice_func=DEFAULT_SETTINGS[\"strategy_choice_func\"],\n",
    "    tau=DEFAULT_SETTINGS[\"tau\"],\n",
    ")\n",
    "\n",
    "traces_df = traces_to_long_df(baseline_X, subsidy_X)\n",
    "\n",
    "spaghetti_path = plot_spaghetti(traces_df, max_traces=100, alpha=0.15)\n",
    "print(\"Saved spaghetti plot:\", spaghetti_path)\n",
    "\n",
    "density_path = plot_density(traces_df, x_bins=50, time_bins=200)\n",
    "print(\"Saved time-evolving density plot:\", density_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c43ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: ratio sweep\n",
    "\n",
    "sweep_df = ratio_sweep_df(\n",
    "    X0_frac=DEFAULT_SCENARIO[\"X0_frac\"],\n",
    "    ratio_values=np.linspace(0.8, 3.5, 31),\n",
    "    scenario_kwargs=DEFAULT_SCENARIO,\n",
    "    T=200,\n",
    "    batch_size=8,\n",
    "    strategy_choice_func=\"logit\",\n",
    "    tau=1.0,\n",
    ")\n",
    "\n",
    "sweep_path = plot_ratio_sweep(sweep_df)\n",
    "print(\"Saved ratio sweep plot:\", sweep_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
